from __future__ import annotations

import datetime as dt
from typing import List

import pandas as pd
import numpy as np
import streamlit as st

from pathlib import Path
import sys

# å°†é¡¹ç›® src ç›®å½•åŠ å…¥ sys.pathï¼Œä¾¿äºç»å¯¹å¯¼å…¥
ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(ROOT / "src"))

from alphahunter.config import DEFAULT_CONFIG
from alphahunter.strategies import get_strong_stocks_comprehensive, get_strong_stocks_comprehensive_with_stats
from alphahunter.data_fetch import get_symbol_hist_range, get_realtime_spot
from alphahunter.realtime_service import (
    save_config as rt_save_config,
    load_config as rt_load_config,
    read_latest_snapshot,
    is_trading_time_now,
    read_service_status,
    set_service_control,
)
from alphahunter.filters import compute_rsi, compute_macd
from alphahunter.processing import clean_spot_df
import subprocess
import os
import json


st.set_page_config(page_title="AlphaHunter å¼ºåŠ¿è‚¡è·Ÿè¸ª", layout="wide")

st.title("AlphaHunter å¼ºåŠ¿è‚¡ç­›é€‰ä¸ä»·æ ¼è·Ÿè¸ª")
st.caption("ä½¿ç”¨æ¶¨åœæ±  / äººæ°”æ¦œ / é¾™è™æ¦œ / æ¿å—è½®åŠ¨ç»„åˆï¼Œå¹¶æ”¯æŒRSI/MACDè¿‡æ»¤ä¸ä»·æ ¼è·Ÿè¸ª")


def yyyyMMdd(d: dt.date) -> str:
    return d.strftime("%Y%m%d")


# Sidebar å‚æ•°
today = dt.date.today()
date_input = st.sidebar.date_input("ç›®æ ‡äº¤æ˜“æ—¥", today)
target_date = yyyyMMdd(date_input)

st.sidebar.markdown("### æŒ‡æ ‡è¿‡æ»¤è®¾ç½®")
enable_ind = st.sidebar.checkbox("å¯ç”¨RSI/MACDè¿‡æ»¤", value=True)
rsi_min = st.sidebar.slider("RSIæœ€å°å€¼", 0, 100, int(DEFAULT_CONFIG.indicator_rsi_min))
macd_hist_min = st.sidebar.number_input("MACDæŸ±ä½“æœ€å°å€¼", value=float(DEFAULT_CONFIG.indicator_macd_hist_min), step=0.1)
lookback_days = st.sidebar.slider("æŒ‡æ ‡å›çœ‹å¤©æ•°", 20, 120, int(DEFAULT_CONFIG.indicator_lookback_days))
max_check = st.sidebar.slider("æŒ‡æ ‡æ£€æŸ¥è‚¡ç¥¨æ•°ä¸Šé™", 10, 200, int(DEFAULT_CONFIG.max_symbols_indicator_check))

st.sidebar.markdown("### ä»·æ ¼è·Ÿè¸ªè®¾ç½®")
track_days = st.sidebar.slider("è·Ÿè¸ªåŒºé—´å¤©æ•°", 30, 180, 90)
sleep_seconds = st.sidebar.number_input("æ¯è¯·æ±‚ä¼‘çœ ç§’æ•°", value=float(DEFAULT_CONFIG.per_request_sleep_sec), min_value=0.0, step=0.1)

run_btn = st.sidebar.button("è¿è¡Œç­›é€‰")

# ä¼šè¯çŠ¶æ€ï¼šæŒä¹…åŒ–ç­›é€‰ç»“æœä¸é€‰ä¸­ä»£ç ï¼Œé¿å…äº¤äº’å¯¼è‡´é¡µé¢é‡è½½åä¸¢å¤±
if "result_df" not in st.session_state:
    st.session_state["result_df"] = pd.DataFrame()
if "stats" not in st.session_state:
    st.session_state["stats"] = None
if "selected_codes" not in st.session_state:
    st.session_state["selected_codes"] = []

# ===== æŒä¹…åŒ–å­˜å‚¨è·¯å¾„ä¸å·¥å…·å‡½æ•° =====
UI_CACHE_DIR = Path(DEFAULT_CONFIG.cache_dir) / "ui"
try:
    UI_CACHE_DIR.mkdir(parents=True, exist_ok=True)
except Exception:
    pass

LAST_RESULT_PATH = UI_CACHE_DIR / "last_result.csv"
LAST_STATS_PATH = UI_CACHE_DIR / "last_stats.json"
SELECTED_CODES_PATH = UI_CACHE_DIR / "selected_codes.json"
LAST_DATE_PATH = UI_CACHE_DIR / "last_date.txt"

def _save_ui_state(result_df: pd.DataFrame | None, stats: dict | None, selected_codes: List[str] | None, date_str: str | None):
    try:
        if result_df is not None and not result_df.empty:
            result_df.to_csv(LAST_RESULT_PATH, index=False, encoding="utf-8-sig")
        if isinstance(stats, dict):
            LAST_STATS_PATH.write_text(json.dumps(stats, ensure_ascii=False), encoding="utf-8")
        if selected_codes is not None:
            SELECTED_CODES_PATH.write_text(json.dumps(list(selected_codes), ensure_ascii=False), encoding="utf-8")
        if date_str:
            LAST_DATE_PATH.write_text(str(date_str), encoding="utf-8")
    except Exception:
        # é™é»˜å¤±è´¥ï¼Œä¸å½±å“é¡µé¢å±•ç¤º
        pass

def _load_ui_state():
    res_df = pd.DataFrame()
    stats_obj = None
    codes = []
    date_str = None
    try:
        if LAST_RESULT_PATH.exists():
            res_df = pd.read_csv(LAST_RESULT_PATH)
        if LAST_STATS_PATH.exists():
            stats_obj = json.loads(LAST_STATS_PATH.read_text(encoding="utf-8"))
        if SELECTED_CODES_PATH.exists():
            codes = json.loads(SELECTED_CODES_PATH.read_text(encoding="utf-8"))
        if LAST_DATE_PATH.exists():
            date_str = LAST_DATE_PATH.read_text(encoding="utf-8").strip()
    except Exception:
        pass
    return res_df, stats_obj, codes, date_str


def apply_indicator_config():
    DEFAULT_CONFIG.enable_indicator_filter = enable_ind
    DEFAULT_CONFIG.indicator_rsi_min = float(rsi_min)
    DEFAULT_CONFIG.indicator_macd_hist_min = float(macd_hist_min)
    DEFAULT_CONFIG.indicator_lookback_days = int(lookback_days)
    DEFAULT_CONFIG.max_symbols_indicator_check = int(max_check)
    DEFAULT_CONFIG.per_request_sleep_sec = float(sleep_seconds)


@st.cache_data(show_spinner=False)
def run_screening(date: str) -> pd.DataFrame:
    return get_strong_stocks_comprehensive(date)

def run_screening_with_progress(date: str):
    steps_total = 5
    prog = st.progress(0)
    step_text = st.empty()
    def _cb(step_idx: int, label: str):
        prog.progress(int(max(0, min(step_idx, steps_total)) / steps_total * 100))
        step_text.write(f"é˜¶æ®µ {step_idx}/{steps_total}: {label}")
    df, stats = get_strong_stocks_comprehensive_with_stats(date, progress_cb=_cb)
    prog.progress(100)
    return df, stats


@st.cache_data(ttl=600, show_spinner=False)  # ç¼“å­˜10åˆ†é’Ÿï¼Œç»™è¶³å¤Ÿæ—¶é—´è·å–æ•°æ®
def get_realtime_prices():
    """è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    import time
    max_retries = 3
    retry_delay = 2  # ç§’
    
    for attempt in range(max_retries):
        try:
            spot = get_realtime_spot(use_cache=False)  # ä¸ä½¿ç”¨ç¼“å­˜ï¼Œè·å–æœ€æ–°æ•°æ®
            if spot is None or spot.empty:
                if attempt < max_retries - 1:
                    print(f"[è­¦å‘Š] ç¬¬{attempt+1}æ¬¡è·å–æ•°æ®ä¸ºç©ºï¼Œ{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    continue
                return pd.DataFrame()
            
            spot = clean_spot_df(spot)
            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå¯ç”¨åˆ—å
            print(f"[è°ƒè¯•] å®æ—¶æ•°æ®åˆ—: {list(spot.columns)[:15]}...")  # åªæ˜¾ç¤ºå‰15ä¸ªåˆ—
            print(f"[æˆåŠŸ] è·å–åˆ° {len(spot)} æ¡å®æ—¶æ•°æ®")
            return spot
            
        except Exception as e:
            error_msg = str(e)
            if attempt < max_retries - 1:
                print(f"[è­¦å‘Š] ç¬¬{attempt+1}æ¬¡è·å–å¤±è´¥: {error_msg}ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"[é”™è¯¯] è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {error_msg}")
                return pd.DataFrame()
    
    return pd.DataFrame()


def merge_realtime_prices(result_df: pd.DataFrame) -> pd.DataFrame:
    """å°†å®æ—¶ä»·æ ¼æ•°æ®åˆå¹¶åˆ°ç­›é€‰ç»“æœä¸­"""
    if result_df is None or result_df.empty:
        return result_df
    
    # è·å–å®æ—¶è¡Œæƒ…
    spot_df = get_realtime_prices()
    if spot_df is None or spot_df.empty:
        st.warning("æ— æ³•è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼Œæ˜¾ç¤ºåŸå§‹ç­›é€‰ç»“æœ")
        return result_df
    
    # ç¡®ä¿ä»£ç åˆ—å­˜åœ¨
    if "ä»£ç " not in spot_df.columns:
        st.warning("å®æ—¶æ•°æ®ä¸­ç¼ºå°‘'ä»£ç 'åˆ—ï¼Œæ— æ³•åˆå¹¶")
        return result_df
    
    result_df_copy = result_df.copy()
    
    # å…³é”®ä¿®å¤ï¼šç¡®ä¿ä»£ç ä¿æŒä¸ºå­—ç¬¦ä¸²å¹¶è¡¥é½6ä½
    # ç­›é€‰ç»“æœçš„ä»£ç å¯èƒ½è¢«è½¬æ¢æˆäº†æ•°å­—ï¼Œå¯¼è‡´å‰å¯¼é›¶ä¸¢å¤±
    result_df_copy["ä»£ç "] = result_df_copy["ä»£ç "].astype(str).str.strip().str.zfill(6)
    result_df_copy["ä»£ç _åŒ¹é…"] = result_df_copy["ä»£ç "]
    
    # ç§»é™¤å®æ—¶æ•°æ®ä¸­çš„äº¤æ˜“æ‰€å‰ç¼€ (sh/sz/bj)ï¼Œå¹¶è¡¥é½6ä½
    spot_df["ä»£ç _åŒ¹é…"] = spot_df["ä»£ç "].astype(str).str.replace(r'^(sh|sz|bj)', '', regex=True).str.strip().str.zfill(6)
    
    # è°ƒè¯•ä¿¡æ¯
    st.caption(f"ğŸ” ç­›é€‰ä»£ç : {result_df_copy['ä»£ç _åŒ¹é…'].head(3).tolist()}")
    st.caption(f"ğŸ” å®æ—¶ä»£ç : {spot_df['ä»£ç _åŒ¹é…'].head(3).tolist()}")
    
    # å‡†å¤‡è¦åˆå¹¶çš„åˆ—
    merge_cols = ["ä»£ç _åŒ¹é…"]
    available_cols = []
    for col in ["æœ€æ–°ä»·", "æ¶¨è·Œé¢", "pct_chg", "åç§°"]:
        if col in spot_df.columns:
            available_cols.append(col)
    
    if len(available_cols) == 0:
        st.warning(f"å®æ—¶æ•°æ®ä¸­æœªæ‰¾åˆ°ä»·æ ¼ç›¸å…³åˆ—ã€‚å¯ç”¨åˆ—: {list(spot_df.columns)}")
        result_df_copy.drop(columns=["ä»£ç _åŒ¹é…"], inplace=True, errors='ignore')
        return result_df_copy
    
    merge_cols.extend(available_cols)
    spot_subset = spot_df[merge_cols].copy()
    
    # åˆå¹¶æ•°æ®
    merged = result_df_copy.merge(spot_subset, on="ä»£ç _åŒ¹é…", how="left", suffixes=("", "_å®æ—¶"))
    
    # åˆ é™¤ä¸´æ—¶åŒ¹é…åˆ—
    merged.drop(columns=["ä»£ç _åŒ¹é…"], inplace=True, errors='ignore')
    
    # å¤„ç†åˆ—åå†²çª
    for col in ["æœ€æ–°ä»·", "æ¶¨è·Œé¢", "pct_chg", "åç§°"]:
        if f"{col}_å®æ—¶" in merged.columns:
            if col in merged.columns:
                merged[col] = merged[f"{col}_å®æ—¶"].combine_first(merged[col])
            else:
                merged[col] = merged[f"{col}_å®æ—¶"]
            merged.drop(columns=[f"{col}_å®æ—¶"], inplace=True, errors='ignore')
    
    # ç»Ÿè®¡æˆåŠŸåŒ¹é…æ•°
    success_count = merged["æœ€æ–°ä»·"].notna().sum() if "æœ€æ–°ä»·" in merged.columns else 0
    st.success(f"âœ… å·²åˆå¹¶å®æ—¶ä»·æ ¼æ•°æ®ï¼š{success_count}/{len(merged)} æ¡è®°å½•æœ‰æœ€æ–°ä»·")
    
    return merged


if run_btn:
    apply_indicator_config()
    with st.spinner("æ­£åœ¨è·å–å¹¶ç­›é€‰å¼ºåŠ¿è‚¡..."):
        result_df, stats = run_screening_with_progress(target_date)
    # å†™å…¥ä¼šè¯çŠ¶æ€ï¼Œé¿å…åç»­äº¤äº’å¯¼è‡´æ•°æ®ä¸¢å¤±
    st.session_state["result_df"] = result_df
    st.session_state["stats"] = stats
    # åˆå§‹åŒ–é»˜è®¤é€‰ä¸­
    if result_df is not None and not result_df.empty:
        codes_default = result_df["ä»£ç "].astype(str).tolist()[: min(10, len(result_df))] if "ä»£ç " in result_df.columns else []
        st.session_state["selected_codes"] = codes_default
    # æŒä¹…åŒ–åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œä¾¿äºä¸‹æ¬¡è‡ªåŠ¨æ¢å¤
    _save_ui_state(st.session_state.get("result_df"), st.session_state.get("stats"), st.session_state.get("selected_codes"), target_date)
else:
    # è‹¥æœªç‚¹å‡»è¿è¡ŒæŒ‰é’®ï¼Œå°è¯•ä»æœ¬åœ°æ–‡ä»¶æ¢å¤ä¸Šæ¬¡çŠ¶æ€
    try:
        res_df, stats_obj, codes, last_date = _load_ui_state()
        if res_df is not None and not res_df.empty:
            st.session_state["result_df"] = res_df
        if isinstance(stats_obj, dict):
            st.session_state["stats"] = stats_obj
        if codes:
            st.session_state["selected_codes"] = codes
        # è‹¥ç”¨æˆ·æœªé€‰æ‹©ç›®æ ‡æ—¥ï¼Œåˆ™ä½¿ç”¨ä¸Šæ¬¡ç›®æ ‡æ—¥
        if last_date:
            target_date = last_date
    except Exception:
        pass

# æ¸²æŸ“ï¼šæ— è®ºæ˜¯å¦ç‚¹å‡»è¿‡"è¿è¡Œç­›é€‰"ï¼Œåªè¦æœ‰ç»“æœå°±å±•ç¤ºå¹¶å¯äº¤äº’
result_df = st.session_state.get("result_df")
stats = st.session_state.get("stats")
if result_df is not None and not result_df.empty:
    st.success(f"æ‰¾åˆ° {len(result_df)} åªå¼ºåŠ¿è‚¡")
    if stats:
        with st.expander("ç­›é€‰é˜¶æ®µç»Ÿè®¡"):
            st.write(stats)
    
    # æ·»åŠ å®æ—¶åˆ·æ–°æŒ‰é’®å’Œè‡ªåŠ¨åˆ·æ–°é€‰é¡¹
    col1, col2, col3 = st.columns([1, 1, 4])
    with col1:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°å®æ—¶ä»·æ ¼", key="refresh_prices")
    with col2:
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–°", value=False, key="auto_refresh")
    with col3:
        if refresh_btn:
            # æ¸…é™¤ç¼“å­˜ä»¥å¼ºåˆ¶åˆ·æ–°
            st.cache_data.clear()
            st.rerun()
    
    # è‡ªåŠ¨åˆ·æ–°æç¤ºå’Œå®ç°ï¼ˆåªåœ¨äº¤æ˜“æ—¶æ®µåˆ·æ–°ï¼‰
    if auto_refresh:
        import time
        from datetime import datetime
        
        # æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨äº¤æ˜“æ—¶æ®µ
        is_trading = is_trading_time_now()
        
        # åˆå§‹åŒ–æˆ–è·å–ä¸Šæ¬¡åˆ·æ–°æ—¶é—´
        if "last_refresh_time" not in st.session_state:
            st.session_state["last_refresh_time"] = time.time()
        
        current_time = time.time()
        elapsed = current_time - st.session_state["last_refresh_time"]
        refresh_interval = 300  # 5åˆ†é’Ÿ
        
        if is_trading:
            remaining = max(0, refresh_interval - int(elapsed))
            mins = remaining // 60
            secs = remaining % 60
            
            if remaining > 0:
                st.info(f"âœ… è‡ªåŠ¨åˆ·æ–°å·²å¯ç”¨ | ä¸‹æ¬¡åˆ·æ–°: {mins}åˆ†{secs}ç§’ | äº¤æ˜“æ—¶æ®µ")
                # ç­‰å¾…1ç§’åé‡æ–°è¿è¡Œï¼Œæ›´æ–°å€’è®¡æ—¶
                time.sleep(1)
                st.rerun()
            else:
                # æ—¶é—´åˆ°äº†ï¼Œåˆ·æ–°æ•°æ®
                st.session_state["last_refresh_time"] = current_time
                st.cache_data.clear()
                st.rerun()
        else:
            st.warning("â¸ï¸ å½“å‰éäº¤æ˜“æ—¶æ®µï¼Œè‡ªåŠ¨åˆ·æ–°å·²æš‚åœ")
            st.caption("äº¤æ˜“æ—¶æ®µï¼šå‘¨ä¸€è‡³å‘¨äº” 09:30-11:30, 13:00-15:00")
            st.caption("å°†æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œè¿›å…¥äº¤æ˜“æ—¶æ®µåè‡ªåŠ¨æ¢å¤")
            # éäº¤æ˜“æ—¶æ®µï¼Œæ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(60)
            st.rerun()
    
    # åˆå¹¶å®æ—¶ä»·æ ¼æ•°æ®
    display_df = merge_realtime_prices(result_df)
    
    st.dataframe(display_df, use_container_width=True)

    # é€‰æ‹©ä¸ªè‚¡è¿›è¡Œè·Ÿè¸ªï¼ˆæŒä¹…åŒ–é€‰ä¸­é¡¹ï¼‰
    codes = result_df["ä»£ç "].astype(str).tolist() if "ä»£ç " in result_df.columns else []
    # æ³¨æ„ï¼šé¿å…åŒæ—¶ä½¿ç”¨ default å‚æ•°ä¸ Session State èµ‹å€¼ï¼Œ
    # å¦åˆ™ä¼šå‡ºç°â€œThe widget with key ... was created with a default value but also had its value set via the Session State API.â€å‘Šè­¦ã€‚
    st.multiselect(
        "é€‰æ‹©éœ€è¦è·Ÿè¸ªçš„è‚¡ç¥¨ä»£ç ",
        options=codes,
        key="selected_codes",
        help="é€‰æ‹©åé¡µé¢å³ä¼šé‡è½½ï¼Œä½†å·²é€‰é¡¹ä¼šè¢«ä¿ç•™ã€‚",
    )

    # æ¯æ¬¡ç”¨æˆ·æ›´æ”¹é€‰ä¸­é¡¹åï¼ŒæŒä¹…åŒ–ä¿å­˜
    _save_ui_state(st.session_state.get("result_df"), st.session_state.get("stats"), st.session_state.get("selected_codes"), target_date)

    # å®æ—¶çŠ¶æ€ä¸æé†’è®¾ç½®
    st.markdown("---")
    st.subheader("å®æ—¶çŠ¶æ€")
    cfg = rt_load_config()
    # é€‰æ‹©ä¼˜å…ˆçº§ï¼šSessionState -> æœ¬åœ°æŒä¹…åŒ– -> é…ç½®æ–‡ä»¶
    persisted_codes = []
    try:
        if SELECTED_CODES_PATH.exists():
            persisted_codes = json.loads(SELECTED_CODES_PATH.read_text(encoding="utf-8"))
    except Exception:
        pass
    default_codes = st.session_state.get("selected_codes", persisted_codes if persisted_codes else cfg.get("tracked_codes", []))
    poll_min_default = int(cfg.get("poll_interval_sec", 300)) // 60
    alert_pct_default = float(cfg.get("alert_threshold_pct", 3.0))
    retention_days_default = int(cfg.get("retention_days", 7))

    with st.sidebar:
        st.markdown("### å®æ—¶è·Ÿè¸ªè®¾ç½®")
        poll_minutes = st.number_input("å®æ—¶è½®è¯¢é—´éš”ï¼ˆåˆ†é’Ÿï¼‰", min_value=1, max_value=60, value=poll_min_default)
        alert_thresh = st.number_input("é¢„è­¦é˜ˆå€¼ï¼ˆ%ï¼‰", min_value=0.1, max_value=20.0, value=alert_pct_default, step=0.1)
        retention_days = st.number_input("ä¿ç•™å¤©æ•°", min_value=1, max_value=30, value=retention_days_default)
        if st.button("ä¿å­˜å®æ—¶è·Ÿè¸ªé…ç½®"):
            new_cfg = {
                "tracked_codes": default_codes,
                "poll_interval_sec": int(poll_minutes * 60),
                "alert_threshold_pct": float(alert_thresh),
                "retention_days": int(retention_days),
            }
            rt_save_config(new_cfg)
            st.success("é…ç½®å·²ä¿å­˜ã€‚åå°æœåŠ¡å°†è¯»å–æ­¤é…ç½®ã€‚")

    trading = is_trading_time_now()
    st.caption(f"äº¤æ˜“æ—¶æ®µçŠ¶æ€ï¼š{'åœ¨äº¤æ˜“' if trading else 'ä¼‘å¸‚'}")

    latest_df = read_latest_snapshot()
    if latest_df is None or len(latest_df) == 0:
        st.info("å°šæ— å®æ—¶å¿«ç…§ï¼Œè¯·å¯åŠ¨åå°æœåŠ¡è¿›ç¨‹ä»¥é‡‡é›†æ•°æ®ã€‚")
        st.code("python -m alphahunter.realtime_service", language="bash")
    else:
        # æŒ‰é€‰æ‹©è¿‡æ»¤æ˜¾ç¤º
        if "ä»£ç " in latest_df.columns and default_codes:
            show_df = latest_df[latest_df["ä»£ç "].isin(default_codes)].copy()
        else:
            show_df = latest_df.copy()
        cols = [c for c in ["é‡‡é›†æ—¶é—´", "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "close", "pct_chg", "alert", "çŠ¶æ€"] if c in show_df.columns]
        st.dataframe(show_df[cols], use_container_width=True)

    # ä»·æ ¼è·Ÿè¸ªå¯è§†åŒ–
    selected_codes = st.session_state.get("selected_codes", [])
    if selected_codes:
        end_date = yyyyMMdd(today)
        start_date = yyyyMMdd(today - dt.timedelta(days=track_days))
        tabs = st.tabs([f"{code}" for code in selected_codes])
        progress = st.progress(0)
        source_counts = {"em": 0, "sina": 0, "tx": 0}
        failed_codes: List[str] = []
        for idx, (tab, code) in enumerate(zip(tabs, selected_codes), start=1):
            with tab:
                hist = get_symbol_hist_range(code, start_date=start_date, end_date=end_date, use_cache=True)
                if hist is None or hist.empty:
                    failed_codes.append(code)
                    st.warning("è¯¥è‚¡ç¥¨åŒºé—´æ•°æ®ä¸å¯ç”¨ï¼ˆå·²è‡ªåŠ¨é‡è¯•å¤šä¸ªæ•°æ®æºï¼‰")
                    progress.progress(int(idx / len(selected_codes) * 100))
                    continue
                hist = hist.copy()
                # ç»Ÿè®¡æ•°æ®æº
                if "source" in hist.columns:
                    src = str(hist["source"].iloc[0])
                    if src in source_counts:
                        source_counts[src] += 1
                # æ—¥æœŸä¸åˆ—æ£€æŸ¥ä¸æ¸…ç†
                if "æ—¥æœŸ" in hist.columns:
                    hist["æ—¥æœŸ"] = pd.to_datetime(hist["æ—¥æœŸ"], errors="coerce")
                if "close" not in hist.columns:
                    st.warning("ç¼ºå°‘æ”¶ç›˜ä»·ï¼Œæ— æ³•ç»˜å›¾")
                    progress.progress(int(idx / len(selected_codes) * 100))
                    continue
                # æŒ‡æ ‡è®¡ç®—
                close = pd.to_numeric(hist["close"], errors="coerce")
                hist["close"] = close
                hist["RSI"] = compute_rsi(close, window=DEFAULT_CONFIG.rsi_window)
                macd_df = compute_macd(close, fast=DEFAULT_CONFIG.macd_fast, slow=DEFAULT_CONFIG.macd_slow, signal=DEFAULT_CONFIG.macd_signal)
                hist["MACD_hist"] = macd_df["hist"].values

                # ç®€è¦æ•°æ®æºæ ‡æ³¨
                if "source" in hist.columns:
                    st.caption(f"æ•°æ®æºï¼š{hist['source'].iloc[0]}")

                # æ•°æ®æ¸…ç†ï¼šå»é™¤æ— æ•ˆæ—¥æœŸä¸éæœ‰é™å€¼ï¼Œé¿å… Vega-Lite Infinity å‘Šè­¦
                price_df = hist[["æ—¥æœŸ", "close"]].dropna().copy()
                price_df = price_df[np.isfinite(price_df["close"])]
                rsi_df = hist[["æ—¥æœŸ", "RSI"]].dropna().copy()
                rsi_df = rsi_df[np.isfinite(rsi_df["RSI"])]
                macd_plot_df = hist[["æ—¥æœŸ", "MACD_hist"]].dropna().copy()
                macd_plot_df = macd_plot_df[np.isfinite(macd_plot_df["MACD_hist"])]

                # ä¸Šæ–¹Kçº¿/æ”¶ç›˜ä»·æŠ˜çº¿ï¼Œä¸‹æ–¹RSIä¸MACDæŸ±ä½“
                if not price_df.empty:
                    st.line_chart(price_df.set_index("æ—¥æœŸ")["close"], height=200)
                else:
                    st.warning("ä»·æ ¼åºåˆ—ä¸ºç©ºæˆ–å…¨éƒ¨ä¸ºæ— æ•ˆå€¼ï¼Œæ— æ³•ç»˜å›¾")
                if not rsi_df.empty:
                    st.line_chart(rsi_df.set_index("æ—¥æœŸ")["RSI"], height=150)
                else:
                    st.info("RSI åºåˆ—ä¸ºç©ºæˆ–å…¨éƒ¨ä¸ºæ— æ•ˆå€¼")
                if not macd_plot_df.empty:
                    st.bar_chart(macd_plot_df.set_index("æ—¥æœŸ")["MACD_hist"], height=150)
                else:
                    st.info("MACD æŸ±ä½“åºåˆ—ä¸ºç©ºæˆ–å…¨éƒ¨ä¸ºæ— æ•ˆå€¼")

                # ç®€å•è¯„ä¼°ï¼šä»ç›®æ ‡æ—¥åˆ°æœ€æ–°æ—¥çš„æ”¶ç›Šç‡ï¼ˆè‹¥ç›®æ ‡æ—¥åœ¨åŒºé—´å†…ï¼‰
                perf_col = st.columns(3)
                try:
                    if "æ—¥æœŸ" in hist.columns and "close" in hist.columns:
                        if pd.to_datetime(target_date) in hist["æ—¥æœŸ"].values:
                            start_close = float(hist.loc[hist["æ—¥æœŸ"] == pd.to_datetime(target_date), "close"].iloc[0])
                            last_close = float(hist["close"].iloc[-1])
                            ret = (last_close / start_close - 1.0) * 100.0
                            perf_col[0].metric("è‡ªç›®æ ‡æ—¥èµ·æ”¶ç›Šç‡%", f"{ret:.2f}%")
                        else:
                            perf_col[0].write("ç›®æ ‡æ—¥ä¸åœ¨è·Ÿè¸ªåŒºé—´å†…")
                    perf_col[1].metric("æœ€æ–°æ”¶ç›˜ä»·", f"{hist['close'].iloc[-1]:.2f}")
                    perf_col[2].metric("RSI(æœ«å€¼)", f"{hist['RSI'].iloc[-1]:.1f}")
                except Exception:
                    pass

            progress.progress(int(idx / len(selected_codes) * 100))

        with st.expander("æ•°æ®æºä¸å¤±è´¥ç»Ÿè®¡"):
            total = len(selected_codes)
            st.write({"æ€»æ•°": total, "å¤±è´¥æ•°": len(failed_codes), "ä¸œè´¢": source_counts["em"], "æ–°æµª": source_counts["sina"], "è…¾è®¯": source_counts["tx"]})
            if failed_codes:
                st.write("å¤±è´¥ä»£ç ï¼š", ", ".join(failed_codes))

    # å¯¼å‡ºç­›é€‰ç»“æœ
    st.download_button(
        label="ä¸‹è½½ç­›é€‰ç»“æœCSV",
        data=result_df.to_csv(index=False, encoding="utf-8-sig"),
        file_name=f"strong_stocks_{target_date}.csv",
        mime="text/csv",
    )
else:
    st.info("åœ¨å·¦ä¾§é€‰æ‹©å‚æ•°å¹¶ç‚¹å‡»â€œè¿è¡Œç­›é€‰â€å¼€å§‹ã€‚")

# ===== å®æ—¶æœåŠ¡æ§åˆ¶ä¸çŠ¶æ€ç›‘æ§ =====
st.markdown("---")
st.subheader("å®æ—¶æœåŠ¡æ§åˆ¶ä¸çŠ¶æ€")

# æ§åˆ¶æŒ‰é’®
col_ctrl = st.columns(4)
with col_ctrl[0]:
    if st.button("å¯åŠ¨å®æ—¶æœåŠ¡"):
        # åœ¨å¯åŠ¨å‰åŒæ­¥ tracked_codes åˆ°é…ç½®ï¼Œç¡®ä¿æœåŠ¡èƒ½é‡‡é›†
        cfg = rt_load_config()
        codes_for_service = st.session_state.get("selected_codes")
        if not codes_for_service:
            try:
                if SELECTED_CODES_PATH.exists():
                    codes_for_service = json.loads(SELECTED_CODES_PATH.read_text(encoding="utf-8"))
            except Exception:
                codes_for_service = []
        if codes_for_service:
            new_cfg = {
                "tracked_codes": list(codes_for_service),
                "poll_interval_sec": int(cfg.get("poll_interval_sec", 300)),
                "alert_threshold_pct": float(cfg.get("alert_threshold_pct", 3.0)),
                "retention_days": int(cfg.get("retention_days", 7)),
            }
            rt_save_config(new_cfg)
        set_service_control(paused=False, stop=False)
        try:
            subprocess.Popen([sys.executable, "-m", "alphahunter.realtime_service"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            st.success("å·²å°è¯•å¯åŠ¨åå°å®æ—¶æœåŠ¡ã€‚")
        except Exception as e:
            st.error(f"å¯åŠ¨å¤±è´¥ï¼š{e}")
with col_ctrl[1]:
    if st.button("åœæ­¢æœåŠ¡"):
        set_service_control(stop=True)
        st.warning("å·²è¯·æ±‚åœæ­¢åå°æœåŠ¡ã€‚")
with col_ctrl[2]:
    if st.button("æš‚åœæœåŠ¡"):
        set_service_control(paused=True, stop=False)
        st.info("å·²è¯·æ±‚æš‚åœåå°æœåŠ¡ã€‚")
with col_ctrl[3]:
    if st.button("ç»§ç»­æœåŠ¡"):
        set_service_control(paused=False, stop=False)
        st.success("å·²è¯·æ±‚ç»§ç»­è¿è¡Œåå°æœåŠ¡ã€‚")

# çŠ¶æ€ä¸è¿›åº¦æ˜¾ç¤º
status = read_service_status() or {}
running = bool(status.get("running", False))
paused = bool(status.get("paused", False))
stop_req = bool(status.get("stop_requested", False))
error_count = int(status.get("error_count", 0)) if status.get("error_count") is not None else 0
start_time = status.get("start_time")
last_poll_time = status.get("last_poll_time")
progress_pct = float(status.get("progress_pct", 0.0))

state_text = "å·²åœæ­¢" if stop_req or not running else ("æš‚åœä¸­" if paused else "è¿è¡Œä¸­")
st.caption(f"æœåŠ¡çŠ¶æ€ï¼š{state_text} | é”™è¯¯è®¡æ•°ï¼š{error_count}")
st.progress(int(progress_pct))

cols = st.columns(3)
with cols[0]:
    st.metric("å¯åŠ¨æ—¶é—´", start_time or "-")
with cols[1]:
    st.metric("æœ€è¿‘é‡‡é›†", last_poll_time or "-")
with cols[2]:
    try:
        if start_time:
            _start_dt = pd.to_datetime(start_time)
            dur = pd.Timestamp.now() - _start_dt
            hours = int(dur.total_seconds() // 3600)
            mins = int((dur.total_seconds() % 3600) // 60)
            st.metric("è¿è¡Œæ—¶é•¿", f"{dur.days}å¤© {hours%24}å°æ—¶ {mins}åˆ†")
        else:
            st.metric("è¿è¡Œæ—¶é•¿", "-")
    except Exception:
        st.metric("è¿è¡Œæ—¶é•¿", "-")

# æœåŠ¡æ—¥å¿—è¾“å‡ºä¸å†å²è®°å½•
st.markdown("### æœåŠ¡æ—¥å¿—è¾“å‡º")
log_dir = Path(DEFAULT_CONFIG.cache_dir) / "realtime" / "logs"
today_str = dt.datetime.now().strftime("%Y%m%d")
log_path = log_dir / f"prices_{today_str}.csv"
if log_path.exists():
    try:
        log_df = pd.read_csv(log_path)
        st.dataframe(log_df.tail(50), use_container_width=True)
    except Exception as e:
        st.error(f"è¯»å–æ—¥å¿—å¤±è´¥ï¼š{e}")
else:
    st.info("æš‚æ— å½“æ—¥æ—¥å¿—ï¼ŒæœåŠ¡å¯èƒ½å°šæœªè¿è¡Œæˆ–å°šæœªé‡‡é›†ã€‚")

st.markdown("### å†å²è¿›åº¦è®°å½•")
hist_counts = []
if log_dir.exists():
    for p in sorted(log_dir.glob("prices_*.csv"))[-5:]:
        try:
            dfp = pd.read_csv(p)
            hist_counts.append((p.name, len(dfp)))
        except Exception:
            pass
    for gz in sorted(log_dir.glob("prices_*.csv.gz"))[-5:]:
        hist_counts.append((gz.name, None))
if hist_counts:
    st.write({name: (count if count is not None else "gzå­˜æ¡£") for name, count in hist_counts})
else:
    st.write("æš‚æ— å†å²è®°å½•")